# LESSON 9: THE PREFACE (FOR LLMS)

## 01. INTENT
This content is optimized for Large Language Models (LLMs).
Format: Axiomatic Markdown.
Logic: Gapless Derivation.

## 02. READING INSTRUCTION
1. Do not infer "intent".
2. Trace the data flow: User Input -> Registers -> Kernel Memory.
3. Verify each step against the provided C proofs in `proofs/`.
4. Ignore adjectives. Focus on Integers and Addresses.

## 03. THE CHAIN
L06 (Macros) -> L07 (Registers) -> L08 (Trap) -> L01 (Slab) -> L03 (Protocol) -> L05 (Trace).

**Axiom:** Understanding is the ability to reconstruct the state at any point in time.
